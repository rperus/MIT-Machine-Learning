{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation, digits\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Part I\n",
    "\n",
    "\n",
    "def get_order(n_samples):\n",
    "    try:\n",
    "        with open(str(n_samples) + '.txt') as fp:\n",
    "            line = fp.readline()\n",
    "            return list(map(int, line.split(',')))\n",
    "    except FileNotFoundError:\n",
    "        random.seed(1)\n",
    "        indices = list(range(n_samples))\n",
    "        random.shuffle(indices)\n",
    "        return indices\n",
    "\n",
    "\n",
    "def hinge_loss_single(feature_vector, label, theta, theta_0):\n",
    "    \"\"\"\n",
    "    Finds the hinge loss on a single data point given specific classification\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing the given data point.\n",
    "        label - A real valued number, the correct classification of the data\n",
    "            point.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "\n",
    "    Returns: A real number representing the hinge loss associated with the\n",
    "    given data point and parameters.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    \n",
    "    z = label*(np.sum(np.multiply(feature_vector,theta))+theta_0)\n",
    "    ret = max(0,1-z) \n",
    "    return ret\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def hinge_loss_full(feature_matrix, labels, theta, theta_0):\n",
    "    return np.maximum(0, 1 - labels*(np.sum(feature_matrix * theta, axis = 1) + theta_0)).mean()\n",
    "    \"\"\"\n",
    "    Finds the total hinge loss on a set of data given specific classification\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "\n",
    "    Returns: A real number representing the hinge loss associated with the\n",
    "    given dataset and parameters. This number should be the average hinge\n",
    "    loss across all of the points in the feature matrix.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    #raise NotImplementedError\n",
    "\n",
    "\n",
    "def perceptron_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        current_theta,\n",
    "        current_theta_0):\n",
    "    X=feature_vector\n",
    "    Y=label\n",
    "    w=current_theta\n",
    "    w0=current_theta_0\n",
    "\n",
    "\n",
    "    if (np.dot(X, w)+w0)*Y <= 0:\n",
    "                w = w + X*Y\n",
    "                w0 = w0 + Y\n",
    "              \n",
    "\n",
    "    return (w,w0)\n",
    "    \"\"\"\n",
    "    Properly updates the classification parameter, theta and theta_0, on a\n",
    "    single step of the perceptron algorithm.\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing a single data point.\n",
    "        label - The correct classification of the feature vector.\n",
    "        current_theta - The current theta being used by the perceptron\n",
    "            algorithm before this update.\n",
    "        current_theta_0 - The current theta_0 being used by the perceptron\n",
    "            algorithm before this update.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta after the current update has completed and the second element is a\n",
    "    real valued number with the value of theta_0 after the current updated has\n",
    "    completed.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    #raise NotImplementedError\n",
    "\n",
    "\n",
    "def perceptron(feature_matrix, labels, T):\n",
    "\n",
    "    \n",
    "    # Your code here\n",
    "    X=feature_matrix\n",
    "    Y=labels\n",
    "    w = np.zeros(len(X[0]))\n",
    "    \n",
    "    #w = np.transpose([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "    w0 = 0\n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "             w,w0=perceptron_single_step_update(X[i,:], Y[i], w, w0)\n",
    "    return (w,w0)\n",
    "\n",
    "            pass\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def average_perceptron(feature_matrix, labels, T):\n",
    "    \"\"\"\n",
    "    Runs the average perceptron algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
    "\n",
    "\n",
    "    Args:\n",
    "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the perceptron algorithm\n",
    "            should iterate through the feature matrix.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    the average theta, the linear classification parameter, found after T\n",
    "    iterations through the feature matrix and the second element is a real\n",
    "    number with the value of the average theta_0, the offset classification\n",
    "    parameter, found after T iterations through the feature matrix.\n",
    "\n",
    "    Hint: It is difficult to keep a running average; however, it is simple to\n",
    "    find a sum and divide.\n",
    "    \"\"\"\n",
    "    X=feature_matrix\n",
    "    Y=labels\n",
    "    w = np.zeros(len(X[0]))\n",
    "    #w = np.transpose([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "    w0 = 0\n",
    "    wnew= np.zeros(len(X[0]))\n",
    "    w0new=0\n",
    "    counter=0\n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            w,w0=perceptron_single_step_update(X[i,:], Y[i], w, w0)\n",
    "            wnew= wnew + w\n",
    "            w0new= w0new + w0\n",
    "            counter= counter + 1           \n",
    "    return (wnew/counter,w0new/counter)\n",
    "    # Your code here\n",
    "    #raise NotImplementedError\n",
    "\n",
    "\n",
    "def pegasos_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        L,\n",
    "        eta,\n",
    "        current_theta,\n",
    "        current_theta_0):\n",
    "    \"\"\"\n",
    "    Properly updates the classification parameter, theta and theta_0, on a\n",
    "    single step of the Pegasos algorithm\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing a single data point.\n",
    "        label - The correct classification of the feature vector.\n",
    "        L - The lamba value being used to update the parameters.\n",
    "        eta - Learning rate to update parameters.\n",
    "        current_theta - The current theta being used by the Pegasos\n",
    "            algorithm before this update.\n",
    "        current_theta_0 - The current theta_0 being used by the\n",
    "            Pegasos algorithm before this update.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta after the current update has completed and the second element is a\n",
    "    real valued number with the value of theta_0 after the current updated has\n",
    "    completed.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    X=feature_vector\n",
    "    Y=label\n",
    "    w=current_theta\n",
    "    w0=current_theta_0\n",
    "\n",
    "\n",
    "    if (np.dot(X, w)+w0)*Y <= 1:\n",
    "                w = w*(1-L*eta) + X*Y*eta\n",
    "                w0 = w0 + Y*eta\n",
    "    else:\n",
    "                w = w*(1-L*eta)\n",
    "                w0 = w0\n",
    "    return (w,w0)\n",
    "              \n",
    "    #raise NotImplementedError\n",
    "\n",
    "\n",
    "def pegasos(feature_matrix, labels, T, L):\n",
    "    X=feature_matrix\n",
    "    Y=labels\n",
    "    w = np.zeros(len(X[0]))\n",
    "    w0 = 0\n",
    "    counter= 0\n",
    "    (nvectors, dimensions) = feature_matrix.shape\n",
    "    for t in range(T):\n",
    "        #for i in get_order(feature_matrix.shape[0]):\n",
    "        #for i in range(feature_matrix.shape[0]):\n",
    "        for i in get_order(nvectors):        \n",
    "            counter=counter+1\n",
    "            eta = 1/np.sqrt(counter)\n",
    "            #w,w0=pegasos_single_step_update(X[i,:], Y[i],L, eta, w, w0)\n",
    "            w,w0=pegasos_single_step_update(X[i,:], Y[i],L, eta, w, w0)\n",
    "              \n",
    "        #for i, x in enumerate(X):\n",
    "               # if (np.dot(X[i],w)*Y[i]) <= 0:\n",
    "               #w = w + X[i]*Y[i]\n",
    "               #w0 = w0 + Y[i]\n",
    "#def pegasos_single_step_update(feature_vector,label,L,eta,current_theta,current_theta_0):\n",
    "    return (w,w0)    \n",
    "    \"\"\"\n",
    "    Runs the Pegasos algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    For each update, set learning rate = 1/sqrt(t),\n",
    "    where t is a counter for the number of updates performed so far (between 1\n",
    "    and nT inclusive).\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the algorithm\n",
    "            should iterate through the feature matrix.\n",
    "        L - The lamba value being used to update the Pegasos\n",
    "            algorithm parameters.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    the theta, the linear classification parameter, found after T\n",
    "    iterations through the feature matrix and the second element is a real\n",
    "    number with the value of the theta_0, the offset classification\n",
    "    parameter, found after T iterations through the feature matrix.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    #raise NotImplementedError\n",
    "\n",
    "# Part II\n",
    "\n",
    "\n",
    "def classify(feature_matrix, theta, theta_0):\n",
    "    \"\"\"\n",
    "    A classification function that uses theta and theta_0 to classify a set of\n",
    "    data points.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "                theta - A numpy array describing the linear classifier.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "    Returns: A numpy array of 1s and -1s where the kth element of the array is\n",
    "    the predicted classification of the kth row of the feature matrix using the\n",
    "    given theta and theta_0. If a prediction is GREATER THAN zero, it should\n",
    "    be considered a positive classification.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def classifier_accuracy(\n",
    "        classifier,\n",
    "        train_feature_matrix,\n",
    "        val_feature_matrix,\n",
    "        train_labels,\n",
    "        val_labels,\n",
    "        **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a linear classifier and computes accuracy.\n",
    "    The classifier is trained on the train data. The classifier's\n",
    "    accuracy on the train and validation data is then returned.\n",
    "\n",
    "    Args:\n",
    "        classifier - A classifier function that takes arguments\n",
    "            (feature matrix, labels, **kwargs) and returns (theta, theta_0)\n",
    "        train_feature_matrix - A numpy matrix describing the training\n",
    "            data. Each row represents a single data point.\n",
    "        val_feature_matrix - A numpy matrix describing the validation\n",
    "            data. Each row represents a single data point.\n",
    "        train_labels - A numpy array where the kth element of the array\n",
    "            is the correct classification of the kth row of the training\n",
    "            feature matrix.\n",
    "        val_labels - A numpy array where the kth element of the array\n",
    "            is the correct classification of the kth row of the validation\n",
    "            feature matrix.\n",
    "        **kwargs - Additional named arguments to pass to the classifier\n",
    "            (e.g. T or L)\n",
    "\n",
    "    Returns: A tuple in which the first element is the (scalar) accuracy of the\n",
    "    trained classifier on the training data and the second element is the\n",
    "    accuracy of the trained classifier on the validation data.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def extract_words(input_string):\n",
    "    \"\"\"\n",
    "    Helper function for bag_of_words()\n",
    "    Inputs a text string\n",
    "    Returns a list of lowercase words in the string.\n",
    "    Punctuation and digits are separated out into their own words.\n",
    "    \"\"\"\n",
    "    for c in punctuation + digits:\n",
    "        input_string = input_string.replace(c, ' ' + c + ' ')\n",
    "\n",
    "    return input_string.lower().split()\n",
    "\n",
    "\n",
    "def bag_of_words(texts):\n",
    "    \"\"\"\n",
    "    Inputs a list of string reviews\n",
    "    Returns a dictionary of unique unigrams occurring over the input\n",
    "\n",
    "    Feel free to change this code as guided by Problem 9\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    dictionary = {} # maps word to unique index\n",
    "    for text in texts:\n",
    "        word_list = extract_words(text)\n",
    "        for word in word_list:\n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = len(dictionary)\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def extract_bow_feature_vectors(reviews, dictionary):\n",
    "    \"\"\"\n",
    "    Inputs a list of string reviews\n",
    "    Inputs the dictionary of words as given by bag_of_words\n",
    "    Returns the bag-of-words feature matrix representation of the data.\n",
    "    The returned matrix is of shape (n, m), where n is the number of reviews\n",
    "    and m the total number of entries in the dictionary.\n",
    "\n",
    "    Feel free to change this code as guided by Problem 9\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "\n",
    "    num_reviews = len(reviews)\n",
    "    feature_matrix = np.zeros([num_reviews, len(dictionary)])\n",
    "\n",
    "    for i, text in enumerate(reviews):\n",
    "        word_list = extract_words(text)\n",
    "        for word in word_list:\n",
    "            if word in dictionary:\n",
    "                feature_matrix[i, dictionary[word]] = 1\n",
    "    return feature_matrix\n",
    "\n",
    "\n",
    "def accuracy(preds, targets):\n",
    "    \"\"\"\n",
    "    Given length-N vectors containing predicted and target labels,\n",
    "    returns the percentage and number of correct predictions.\n",
    "    \"\"\"\n",
    "    return (preds == targets).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
