{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b522e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40f64c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTILS\n",
    "import pickle, gzip, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "\n",
    "\n",
    "def plot_images(X):\n",
    "    if X.ndim == 1:\n",
    "        X = np.array([X])\n",
    "    num_images = X.shape[0]\n",
    "    num_rows = math.floor(math.sqrt(num_images))\n",
    "    num_cols = math.ceil(num_images/num_rows)\n",
    "    for i in range(num_images):\n",
    "        reshaped_image = X[i,:].reshape(28,28)\n",
    "        plt.subplot(num_rows, num_cols, i+1)\n",
    "        plt.imshow(reshaped_image, cmap = cm.Greys_r)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pick_examples_of(X, Y, labels, total_count):\n",
    "    bool_arr = None\n",
    "    for label in labels:\n",
    "        bool_arr_for_label = (Y == label)\n",
    "        if bool_arr is None:\n",
    "            bool_arr = bool_arr_for_label\n",
    "        else:\n",
    "            bool_arr |= bool_arr_for_label\n",
    "    filtered_x = X[bool_arr]\n",
    "    filtered_y = Y[bool_arr]\n",
    "    return (filtered_x[:total_count], filtered_y[:total_count])\n",
    "\n",
    "\n",
    "def extract_training_and_test_examples_with_labels(train_x, train_y, test_x, test_y, labels, training_count, test_count):\n",
    "    filtered_train_x, filtered_train_y = pick_examples_of(train_x, train_y, labels, training_count)\n",
    "    filtered_test_x, filtered_test_y = pick_examples_of(test_x, test_y, labels, test_count)\n",
    "    return (filtered_train_x, filtered_train_y, filtered_test_x, filtered_test_y)\n",
    "\n",
    "def write_pickle_data(data, file_name):\n",
    "    f = gzip.open(file_name, 'wb')\n",
    "    pickle.dump(data, f)\n",
    "    f.close()\n",
    "\n",
    "def read_pickle_data(file_name):\n",
    "    f = gzip.open(file_name, 'rb')\n",
    "    data = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "def get_MNIST_data():\n",
    "    \"\"\"\n",
    "    Reads mnist dataset from file\n",
    "\n",
    "    Returns:\n",
    "        train_x - 2D Numpy array (n, d) where each row is an image\n",
    "        train_y - 1D Numpy array (n, ) where each row is a label\n",
    "        test_x  - 2D Numpy array (n, d) where each row is an image\n",
    "        test_y  - 1D Numpy array (n, ) where each row is a label\n",
    "\n",
    "    \"\"\"\n",
    "    train_set, valid_set, test_set = read_pickle_data('../Datasets/mnist.pkl.gz')\n",
    "    train_x, train_y = train_set\n",
    "    valid_x, valid_y = valid_set\n",
    "    train_x = np.vstack((train_x, valid_x))\n",
    "    train_y = np.append(train_y, valid_y)\n",
    "    test_x, test_y = test_set\n",
    "    return (train_x, train_y, test_x, test_y)\n",
    "\n",
    "def load_train_and_test_pickle(file_name):\n",
    "    train_x, train_y, test_x, test_y = read_pickle_data(file_name)\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "# returns the feature set in a numpy ndarray\n",
    "def load_CSV(filename):\n",
    "    stuff = np.asarray(np.loadtxt(open(filename, 'rb'), delimiter=','))\n",
    "    return stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bbc13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6401f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = get_MNIST_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88219a38",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'center_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19448/2684933830.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m###Correction note:  the following 4 lines have been modified since release.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrain_x_centered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_means\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcenter_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mpcs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprincipal_components\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x_centered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mtrain_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproject_onto_PC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpcs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_means\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'center_data' is not defined"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# 7. Classification Using Manually Crafted Features\n",
    "#######################################################################\n",
    "\n",
    "## Dimensionality reduction via PCA ##\n",
    "\n",
    "# TODO: First fill out the PCA functions in features.py as the below code depends on them.\n",
    "\n",
    "\n",
    "n_components = 18\n",
    "\n",
    "###Correction note:  the following 4 lines have been modified since release.\n",
    "train_x_centered, feature_means = center_data(train_x)\n",
    "pcs = principal_components(train_x_centered)\n",
    "train_pca = project_onto_PC(train_x, pcs, n_components, feature_means)\n",
    "test_pca = project_onto_PC(test_x, pcs, n_components, feature_means)\n",
    "\n",
    "# train_pca (and test_pca) is a representation of our training (and test) data\n",
    "# after projecting each example onto the first 18 principal components.\n",
    "\n",
    "\n",
    "# TODO: Train your softmax regression model using (train_pca, train_y)\n",
    "#       and evaluate its accuracy on (test_pca, test_y).\n",
    "\n",
    "\n",
    "# TODO: Use the plot_PC function in features.py to produce scatterplot\n",
    "#       of the first 100 MNIST images, as represented in the space spanned by the\n",
    "#       first 2 principal components found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef692ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_onto_PC(X, pcs, n_components, feature_means):\n",
    "    \"\"\"\n",
    "    Given principal component vectors pcs = principal_components(X)\n",
    "    this function returns a new data array in which each sample in X\n",
    "    has been projected onto the first n_components principcal components.\n",
    "    \"\"\"\n",
    "    # TODO: first center data using the feature_means\n",
    "    # TODO: Return the projection of the centered dataset\n",
    "    #       on the first n_components principal components.\n",
    "    #       This should be an array with dimensions: n x n_components.\n",
    "    # Hint: these principal components = first n_components columns\n",
    "    #       of the eigenvectors returned by principal_components().\n",
    "    #       Note that each eigenvector is already be a unit-vector,\n",
    "    #       so the projection may be done using matrix multiplication.\n",
    "    center_data=  X - feature_means\n",
    "    V = pcs[:,:n_components]\n",
    "    projection = np.dot(center_data,V)\n",
    "    return projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a451785",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19448/1239753933.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mproject_onto_PC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpcs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_means\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "project_onto_PC(X, pcs, n_components, feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55efe0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions which are already complete, for you to use ###\n",
    "\n",
    "def cubic_features(X):\n",
    "    \"\"\"\n",
    "    Returns a new dataset with features given by the mapping\n",
    "    which corresponds to the cubic kernel.\n",
    "    \"\"\"\n",
    "    n, d = X.shape  # dataset size, input dimension\n",
    "    X_withones = np.ones((n, d + 1))\n",
    "    X_withones[:, :-1] = X\n",
    "    new_d = 0  # dimension of output\n",
    "    new_d = int((d + 1) * (d + 2) * (d + 3) / 6)\n",
    "\n",
    "    new_data = np.zeros((n, new_d))\n",
    "    col_index = 0\n",
    "    for x_i in range(n):\n",
    "        X_i = X[x_i]\n",
    "        X_i = X_i.reshape(1, X_i.size)\n",
    "\n",
    "        if d > 2:\n",
    "            comb_2 = np.matmul(np.transpose(X_i), X_i)\n",
    "\n",
    "            unique_2 = comb_2[np.triu_indices(d, 1)]\n",
    "            unique_2 = unique_2.reshape(unique_2.size, 1)\n",
    "            comb_3 = np.matmul(unique_2, X_i)\n",
    "            keep_m = np.zeros(comb_3.shape)\n",
    "            index = 0\n",
    "            for i in range(d - 1):\n",
    "                keep_m[index + np.arange(d - 1 - i), i] = 0\n",
    "\n",
    "                tri_keep = np.triu_indices(d - 1 - i, 1)\n",
    "\n",
    "                correct_0 = tri_keep[0] + index\n",
    "                correct_1 = tri_keep[1] + i + 1\n",
    "\n",
    "                keep_m[correct_0, correct_1] = 1\n",
    "                index += d - 1 - i\n",
    "\n",
    "            unique_3 = np.sqrt(6) * comb_3[np.nonzero(keep_m)]\n",
    "\n",
    "            new_data[x_i, np.arange(unique_3.size)] = unique_3\n",
    "            col_index = unique_3.size\n",
    "\n",
    "    for i in range(n):\n",
    "        newdata_colindex = col_index\n",
    "        for j in range(d + 1):\n",
    "            new_data[i, newdata_colindex] = X_withones[i, j]**3\n",
    "            newdata_colindex += 1\n",
    "            for k in range(j + 1, d + 1):\n",
    "                new_data[i, newdata_colindex] = X_withones[i, j]**2 * X_withones[i, k] * (3**(0.5))\n",
    "                newdata_colindex += 1\n",
    "\n",
    "                new_data[i, newdata_colindex] = X_withones[i, j] * X_withones[i, k]**2 * (3**(0.5))\n",
    "                newdata_colindex += 1\n",
    "\n",
    "                if k < d:\n",
    "                    new_data[i, newdata_colindex] = X_withones[i, j] * X_withones[i, k] * (6**(0.5))\n",
    "                    newdata_colindex += 1\n",
    "\n",
    "    return new_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb810e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_data(X):\n",
    "    \"\"\"\n",
    "    Returns a centered version of the data, where each feature now has mean = 0\n",
    "\n",
    "    Args:\n",
    "        X - n x d NumPy array of n data points, each with d features\n",
    "\n",
    "    Returns:\n",
    "        - (n, d) NumPy array X' where for each i = 1, ..., n and j = 1, ..., d:\n",
    "        X'[i][j] = X[i][j] - means[j]       \n",
    "\t- (d, ) NumPy array with the columns means\n",
    "\n",
    "    \"\"\"\n",
    "    feature_means = X.mean(axis=0)\n",
    "    return (X - feature_means), feature_means\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "609ee8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def principal_components(centered_data):\n",
    "    \"\"\"\n",
    "    Returns the principal component vectors of the data, sorted in decreasing order\n",
    "    of eigenvalue magnitude. This function first calculates the covariance matrix\n",
    "    and then finds its eigenvectors.\n",
    "\n",
    "    Args:\n",
    "        centered_data - n x d NumPy array of n data points, each with d features\n",
    "\n",
    "    Returns:\n",
    "        d x d NumPy array whose columns are the principal component directions sorted\n",
    "        in descending order by the amount of variation each direction (these are\n",
    "        equivalent to the d eigenvectors of the covariance matrix sorted in descending\n",
    "        order of eigenvalues, so the first column corresponds to the eigenvector with\n",
    "        the largest eigenvalue\n",
    "    \"\"\"\n",
    "    scatter_matrix = np.dot(centered_data.transpose(), centered_data)\n",
    "    eigen_values, eigen_vectors = np.linalg.eig(scatter_matrix)\n",
    "    # Re-order eigenvectors by eigenvalue magnitude:\n",
    "    idx = eigen_values.argsort()[::-1]\n",
    "    eigen_values = eigen_values[idx]\n",
    "    eigen_vectors = eigen_vectors[:, idx]\n",
    "    return eigen_vectors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d293ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Correction note:  Differing from the release, this function takes an extra input feature_means.\n",
    "\n",
    "def plot_PC(X, pcs, labels, feature_means):\n",
    "    \"\"\"\n",
    "    Given the principal component vectors as the columns of matrix pcs,\n",
    "    this function projects each sample in X onto the first two principal components\n",
    "    and produces a scatterplot where points are marked with the digit depicted in\n",
    "    the corresponding image.\n",
    "    labels = a numpy array containing the digits corresponding to each image in X.\n",
    "    \"\"\"\n",
    "    pc_data = project_onto_PC(X, pcs, n_components=2, feature_means=feature_means)\n",
    "    text_labels = [str(z) for z in labels.tolist()]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(pc_data[:, 0], pc_data[:, 1], alpha=0, marker=\".\")\n",
    "    for i, txt in enumerate(text_labels):\n",
    "        ax.annotate(txt, (pc_data[i, 0], pc_data[i, 1]))\n",
    "    ax.set_xlabel('PC 1')\n",
    "    ax.set_ylabel('PC 2')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Correction note:  Differing from the release, this function takes an extra input feature_means.\n",
    "\n",
    "def reconstruct_PC(x_pca, pcs, n_components, X, feature_means):\n",
    "    \"\"\"\n",
    "    Given the principal component vectors as the columns of matrix pcs,\n",
    "    this function reconstructs a single image from its principal component\n",
    "    representation, x_pca.\n",
    "    X = the original data to which PCA was applied to get pcs.\n",
    "    \"\"\"\n",
    "    x_reconstructed = np.dot(x_pca, pcs[:, range(n_components)].T) + feature_means\n",
    "    return x_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf060957",
   "metadata": {},
   "source": [
    "# 10. Kernel Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54cddc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_kernel(X, Y, c, p):\n",
    "    kernel_matrix = (np.dot(X,np.transpose(Y)) + c)**p\n",
    "    return kernel_matrix\n",
    "\n",
    "    \"\"\"\n",
    "        Compute the polynomial kernel between two matrices X and Y::\n",
    "            K(x, y) = (<x, y> + c)^p\n",
    "        for each pair of rows x in X and y in Y.\n",
    "\n",
    "        Args:\n",
    "            X - (n, d) NumPy array (n datapoints each with d features)\n",
    "            Y - (m, d) NumPy array (m datapoints each with d features)\n",
    "            c - a coefficient to trade off high-order and low-order terms (scalar)\n",
    "            p - the degree of the polynomial kernel\n",
    "\n",
    "        Returns:\n",
    "            kernel_matrix - (n, m) Numpy array containing the kernel matrix\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X, Y, gamma):\n",
    "    kernel_matrix = np.zeros((X.shape[0],Y.shape[0]))\n",
    "    for i,x in enumerate(X):\n",
    "        for j,y in enumerate(Y):\n",
    "            kernel_matrix[i,j] = np.exp(-gamma*(np.linalg.norm(x-y))**2)\n",
    "    return kernel_matrix\n",
    "    \n",
    "    \"\"\"\n",
    "        Compute the Gaussian RBF kernel between two matrices X and Y::\n",
    "            K(x, y) = exp(-gamma ||x-y||^2)\n",
    "        for each pair of rows x in X and y in Y.\n",
    "\n",
    "        Args:\n",
    "            X - (n, d) NumPy array (n datapoints each with d features)\n",
    "            Y - (m, d) NumPy array (m datapoints each with d features)\n",
    "            gamma - the gamma parameter of gaussian function (scalar)\n",
    "\n",
    "        Returns:\n",
    "            kernel_matrix - (n, m) Numpy array containing the kernel matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
