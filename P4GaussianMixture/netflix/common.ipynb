{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b19a3201",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Mixture model for collaborative filtering\"\"\"\n",
    "from typing import NamedTuple, Tuple\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle, Arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c62caf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixture(NamedTuple):\n",
    "    \"\"\"Tuple holding a gaussian mixture\"\"\"\n",
    "    mu: np.ndarray  # (K, d) array - each row corresponds to a gaussian component mean\n",
    "    var: np.ndarray  # (K, ) array - each row corresponds to the variance of a component\n",
    "    p: np.ndarray  # (K, ) array = each row corresponds to the weight of a component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7808f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(X: np.ndarray, K: int,\n",
    "         seed: int = 0) -> Tuple[GaussianMixture, np.ndarray]:\n",
    "    \"\"\"Initializes the mixture model with random points as initial\n",
    "    means and uniform assingments\n",
    "\n",
    "    Args:\n",
    "        X: (n, d) array holding the data\n",
    "        K: number of components\n",
    "        seed: random seed\n",
    "\n",
    "    Returns:\n",
    "        mixture: the initialized gaussian mixture\n",
    "        post: (n, K) array holding the soft counts\n",
    "            for all components for all examples\n",
    "\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n, _ = X.shape\n",
    "    p = np.ones(K) / K\n",
    "\n",
    "    # select K random points as initial means\n",
    "    mu = X[np.random.choice(n, K, replace=False)]\n",
    "    var = np.zeros(K)\n",
    "    # Compute variance\n",
    "    for j in range(K):\n",
    "        var[j] = ((X - mu[j])**2).mean()\n",
    "\n",
    "    mixture = GaussianMixture(mu, var, p)\n",
    "    post = np.ones((n, K)) / K\n",
    "\n",
    "    return mixture, post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37792034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(X: np.ndarray, mixture: GaussianMixture, post: np.ndarray,\n",
    "         title: str):\n",
    "    \"\"\"Plots the mixture model for 2D data\"\"\"\n",
    "    _, K = post.shape\n",
    "\n",
    "    percent = post / post.sum(axis=1).reshape(-1, 1)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.title.set_text(title)\n",
    "    ax.set_xlim((-20, 20))\n",
    "    ax.set_ylim((-20, 20))\n",
    "    r = 0.25\n",
    "    color = [\"r\", \"b\", \"k\", \"y\", \"m\", \"c\"]\n",
    "    for i, point in enumerate(X):\n",
    "        theta = 0\n",
    "        for j in range(K):\n",
    "            offset = percent[i, j] * 360\n",
    "            arc = Arc(point,\n",
    "                      r,\n",
    "                      r,\n",
    "                      0,\n",
    "                      theta,\n",
    "                      theta + offset,\n",
    "                      edgecolor=color[j])\n",
    "            ax.add_patch(arc)\n",
    "            theta += offset\n",
    "    for j in range(K):\n",
    "        mu = mixture.mu[j]\n",
    "        sigma = np.sqrt(mixture.var[j])\n",
    "        circle = Circle(mu, sigma, color=color[j], fill=False)\n",
    "        ax.add_patch(circle)\n",
    "        legend = \"mu = ({:0.2f}, {:0.2f})\\n stdv = {:0.2f}\".format(\n",
    "            mu[0], mu[1], sigma)\n",
    "        ax.text(mu[0], mu[1], legend)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12ff08a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(X, Y):\n",
    "    return np.sqrt(np.mean((X - Y)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a53c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bic(X: np.ndarray, mixture: GaussianMixture,\n",
    "        log_likelihood: float) -> float:\n",
    "    \"\"\"Computes the Bayesian Information Criterion for a\n",
    "    mixture of gaussians\n",
    "\n",
    "    Args:\n",
    "        X: (n, d) array holding the data\n",
    "        mixture: a mixture of spherical gaussian\n",
    "        log_likelihood: the log-likelihood of the data\n",
    "\n",
    "    Returns:\n",
    "        float: the BIC for this mixture\n",
    "    \"\"\"\n",
    "    n = X.shape[0]    \n",
    "    p = 0\n",
    "    \n",
    "    for i in range(len(mixture)):\n",
    "        if i == 0:\n",
    "            p = mixture[i].shape[0] * mixture[i].shape[1] +p\n",
    "        else:\n",
    "            p = mixture[i].shape[0]   +p\n",
    "    p = p - 1\n",
    "    \n",
    "    return  log_likelihood - (p*np.log(n))/2.0\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a4a7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('toy_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0b53059",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mixture' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6684/3804614764.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmixture\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mixture' is not defined"
     ]
    }
   ],
   "source": [
    "bic(X, mixture,log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c4937af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6684/2290212047.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# Run Naive EM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mmixtures_EM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposts_EM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosts_EM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mnaive_em\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# Print lowest cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\OneDrive\\Python\\MIT\\P4GaussianMixture\\netflix\\naive_em.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(X, mixture, post)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mfloat\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlikelihood\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0massignment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \"\"\"\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import kmeans\n",
    "import common\n",
    "import naive_em\n",
    "import em\n",
    "\n",
    "X = np.loadtxt(\"toy_data.txt\")\n",
    "\n",
    "########## Begin: kMeans vs EM (and BIC) #############\n",
    "K = [1, 2, 3, 4]    # Clusters to try\n",
    "seeds = [0, 1, 2, 3, 4]     # Seeds to try\n",
    "\n",
    "# Costs for diff. seeds\n",
    "costs_kMeans = [0, 0, 0, 0, 0]\n",
    "costs_EM = [0, 0, 0, 0, 0]\n",
    "\n",
    "# Best seed for cluster based on lowest costs \n",
    "best_seed_kMeans = [0, 0, 0, 0]\n",
    "best_seed_EM = [0, 0, 0, 0]\n",
    "\n",
    "# Mixtures for best seeds\n",
    "mixtures_kMeans = [0, 0, 0, 0, 0]\n",
    "mixtures_EM = [0, 0, 0, 0, 0]\n",
    "\n",
    "# Posterior probs. for best seeds\n",
    "posts_kMeans = [0, 0, 0, 0, 0]\n",
    "posts_EM = [0, 0, 0, 0, 0]\n",
    "\n",
    "# BIC score of cluster\n",
    "bic = [0., 0., 0., 0.]\n",
    "\n",
    "for k in range(len(K)):\n",
    "    for i in range(len(seeds)):\n",
    "        \n",
    "        # Run kMeans\n",
    "        mixtures_kMeans[i], posts_kMeans[i], costs_kMeans[i] = \\\n",
    "        kmeans.run(X, *common.init(X, K[k], seeds[i]))\n",
    "        \n",
    "        # Run Naive EM\n",
    "        mixtures_EM[i], posts_EM[i], costs_EM[i] = \\\n",
    "        naive_em.run(X, *common.init(X, K[k], seeds[i]))\n",
    "    \n",
    "    # Print lowest cost\n",
    "    print(\"=============== Clusters:\", k+1, \"======================\")\n",
    "    print(\"Lowest cost using kMeans is:\", np.min(costs_kMeans))\n",
    "    print(\"Highest log likelihood using EM is:\", np.max(costs_EM))\n",
    "    \n",
    "    # Save best seed for plotting\n",
    "    best_seed_kMeans[k] = np.argmin(costs_kMeans)\n",
    "    best_seed_EM[k] = np.argmax(costs_EM) \n",
    "    \n",
    "    # Plot kMeans and EM results\n",
    "    common.plot(X, \n",
    "                mixtures_kMeans[best_seed_kMeans[k]], \n",
    "                posts_kMeans[best_seed_kMeans[k]], \n",
    "                title=\"kMeans\")\n",
    "\n",
    "    common.plot(X, \n",
    "                mixtures_EM[best_seed_EM[k]], \n",
    "                posts_EM[best_seed_EM[k]], \n",
    "                title=\"EM\") \n",
    "    \n",
    "    #BIC score for EM\n",
    "    bic[k] = common.bic(X, mixtures_EM[best_seed_EM[k]], np.max(costs_EM))\n",
    "    \n",
    "# Print the best K based on BIC\n",
    "print(\"================= BIC ====================\")\n",
    "print(\"Best K is:\", np.argmax(bic)+1)\n",
    "print(\"BIC for the best K is:\", np.max(bic))\n",
    " \n",
    "########## End: kMeans vs EM (and BIC) #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1480b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
